---
---


@article{Abdulmumin:2019aa,
 abstract={Words embedding (distributed word vector representations) have become an essential component of many natural language processing (NLP) tasks such as machine translation, sentiment analysis, word analogy, named entity recognition and word similarity. Despite this, the only work that provides word vectors for Hausa language is that of Bojanowski et al. [1] trained using fastText, consisting of only a few words vectors. This work presents words embedding models using Word2Vec's Continuous Bag of Words (CBoW) and Skip Gram (SG) models. The models, hauWE (Hausa Words Embedding), are bigger and better than the only previous model, making them more useful in NLP tasks. To compare the models, they were used to predict the 10 most similar words to 30 randomly selected Hausa words. hauWE CBoW's 88.7% and hauWE SG's 79.3% prediction accuracy greatly outperformed Bojanowski et al. [1]'s 22.3%.},
 author={Idris Abdulmumin and Bashir Shehu Galadanci},
 bdsk-url-1={https://arxiv.org/pdf/1911.10708.pdf},
 bdsk-url-2={https://arxiv.org/abs/1911.10708},
 bdsk-url-3={https://doi.org/10.1109/NigeriaComputConf45974.2019.8949674},
 date-added={2020-11-07 05:00:32 +0000},
 date-modified={2020-11-07 05:00:32 +0000},
 doi={10.1109/NigeriaComputConf45974.2019.8949674},
 eprint={1911.10708},
 month={11},
 title={hauWE: Hausa Words Embedding for Natural Language Processing},
 url={https://arxiv.org/pdf/1911.10708.pdf},
 year={2019},
 selected={true}
}


@article{Abdulmumin:2020aa,
 abstract={Improving neural machine translation (NMT) models using the back-translations of the monolingual target data (synthetic parallel data) is currently the state-of-the-art approach for training improved translation systems. The quality of the backward system - which is trained on the available parallel data and used for the back-translation - has been shown in many studies to affect the performance of the final NMT model. In low resource conditions, the available parallel data is usually not enough to train a backward model that can produce the qualitative synthetic data needed to train a standard translation model. This work proposes a self-training strategy where the output of the backward model is used to improve the model itself through the forward translation technique. The technique was shown to improve baseline low resource IWSLT'14 English-German and IWSLT'15 English-Vietnamese backward translation models by 11.06 and 1.5 BLEUs respectively. The synthetic data generated by the improved English-German backward model was used to train a forward model which out-performed another forward model trained using standard back-translation by 2.7 BLEU.},
 author={Idris Abdulmumin and Bashir Shehu Galadanci and Abubakar Isa},
 bdsk-url-1={https://arxiv.org/pdf/2006.02876.pdf},
 bdsk-url-2={https://arxiv.org/abs/2006.02876},
 date-added={2020-11-07 05:02:01 +0000},
 date-modified={2020-11-07 05:02:01 +0000},
 eprint={2006.02876},
 month={06},
 title={Using Self-Training to Improve Back-Translation in Low Resource Neural Machine Translation},
 url={https://arxiv.org/pdf/2006.02876.pdf},
 year={2020}
}


@inproceedings{abdulmumin-EtAl:2022:LREC,
 address={Marseille, France},
 author={Abdulmumin, Idris  and  Dash, Satya Ranjan  and  Dawud, Musa Abdullahi  and  Parida, Shantipriya  and  Muhammad, Shamsuddeen  and others},
 booktitle={Proceedings of the Language Resources and Evaluation Conference},
 month={6},
 pages={6471--6479},
 publisher={European Language Resources Association},
 title={Hausa Visual Genome: A Dataset for Multi-Modal English to Hausa Machine Translation},
 url={https://aclanthology.org/2022.lrec-1.694},
 year={2022}
}

@inproceedings{abdulmumin-EtAl:2022:WMT,
  address  ={Abu Dhabi},
  author   ={Abdulmumin, Idris  and  Beukman, Michael  and  Alabi, Jesujoba  and  Emezue, Chris Chinenye  and  Chimoto, Everlyn  and  Adewumi, Tosin  and Muhammad, Shamsuddeen  and others},
  booktitle={Proceedings of the Seventh Conference on Machine Translation},
  month    ={December},
  pages    ={1001--1014},
  publisher={Association for Computational Linguistics},
  title    ={Separating Grains from the Chaff: Using Data Filtering to Improve Multilingual Translation for Low-Resourced African Languages},
  url      ={https://arxiv.org/abs/2210.10692},
  year     ={2022}
}

@article{Abubakar2021,
 author={Amina Imam Abubakar and Abubakar Roko and Aminu Muhammad Bui and Ibrahim Saidu},
 doi={10.14569/IJACSA.2021.0120913},
 journal={International Journal of Advanced Computer Science and Applications},
 number={9},
 publisher={The Science and Information Organization},
 title={An Enhanced Feature Acquisition for Sentiment Analysis of English and Hausa Tweets},
 url={http://dx.doi.org/10.14569/IJACSA.2021.0120913},
 volume={12},
 year={2021}
}

@inproceedings{aliyu-2022-herdphobia,
 address={Abu Dhabi, United Arab Emirates},
 author={Saminu Aliyu and Gregory Wajiga and Muhammad Murtala and Shamsuddeen Muhammad and Idris Abdulmumin and Ibrahim Ahmad},
 booktitle={Proceedings of the Sixth Workshop on Widening Natural Language Processing},
 month={December},
 publisher={Association for Computational Linguistics},
 title={HERDPhobia: A Dataset for Hate Speech Detection against Fulani Herdsmen in Nigeria},
 url={https://aclanthology.org/2022.winlp-1.0},
 year={2022}
}

@inproceedings{Abubakar2019HausaWA,
  title={Hausa WordNet: An Electronic Lexical Resource},
  author={Amina Imam Abubakar and Abubakar Roko and A. B. Muhammad and Ibrahim Saidu},
  year={2019}
}

% This is a preprint, not yet published
@unpublished{hausanlp-semeval-2023,
  author={Saminu Aliyu and Saheed Abdullahi and Shamsuddeen Hassan Muhammad and Ibrahim Sa'id Ahmad and Idris Abdulmumin and Aliyu Yusuf and Falalu Lawan},
  title ={HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-information for Multi-level Sexism Classification},
  year={2023}
}

% This is a preprint, not yet published
@unpublished{havqa-2023,
 author={Shantipriya Parida and Idris Abdulmumin and Shamsuddeen Hassan Muhammad and Aneesh Bose and Guneet Singh Kohli and Ibrahim Said Ahmad and Ketan Kotwal and Sayan Deb Sarkar and Ond≈ôej Bojar and Habeebah Kakudi},
 title={HaVQA: A Dataset for Visual Question Answering and Multimodal Research in Hausa Language},
 year={2023}
}

@misc{https://doi.org/10.48550/arxiv.2302.08956,
  author   ={Muhammad, Shamsuddeen Hassan and Abdulmumin, Idris and Ayele, Abinew Ali and Ousidhoum, Nedjma and Adelani, David Ifeoluwa and Yimam, Seid Muhie and Ahmad, Ibrahim Sa'id and Beloucif, Meriem and Mohammad, Saif and Ruder, Sebastian and others},
  doi      ={10.48550/ARXIV.2302.08956},
  publisher={arXiv},
  title    ={AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages},
  url      ={https://arxiv.org/abs/2302.08956},
  year     ={2023}
}

@inproceedings{maitama2014text,
 author={Maitama, Jaafar Zubairu and Haruna, Usman and Gambo, Abdullahi Ya'u and Thomas, Bimba Andrew and Idris, Norisma Binti and Gital, Abdulsalam Ya'u and Abubakar, Adamu I},
 booktitle={The 5th International Conference on Information and Communication Technology for The Muslim World (ICT4M)},
 organization={IEEE},
 pages={1--4},
 title={Text normalization algorithm for facebook chats in hausa language},
 year={2014},
 pdf={maitama-2014-text.pdf}
}

@misc{muhammad2022naijasenti,
 archiveprefix={arXiv},
 author={Shamsuddeen Hassan Muhammad and David Ifeoluwa Adelani and Sebastian Ruder and Ibrahim Said Ahmad and Idris Abdulmumin and Bello Shehu Bello and Monojit Choudhury and others},
 eprint={2201.08277},
 primaryclass={cs.CL},
 title={NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual Sentiment Analysis},
 year={2022},
 pdf={muhammad-2022-naijasenti.pdf}
}

@inproceedings{muhammad-etal-2023-semeval,
 address={Toronto, Canada},
 author={Muhammad, Shamsuddeen and
Abdulmumin, Idris and
Yimam, Seid Muhie and
Adelani, David Ifeoluwa and
Ahmad, Ibrahim Sa'id and
Ousidhoum, Nedjma and
Ayele, Abinew Ali and
Mohammad, Saif M. and
Beloucif, Meriem and
Ruder, Sebastian},
 booktitle={Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)},
 month={July},
 title={SemEval 2023 Task 12: Sentiment Analysis for African Languages (AfriSenti-SemEval)},
 url={https://arxiv.org/abs/2304.06845},
 year={2023}
}

@misc{nekoto2020participatory,
  archiveprefix={arXiv},
  author       ={Wilhelmina Nekoto and Vukosi Marivate and Tshinondiwa Matsila and Timi Fasubaa and Tajudeen Kolawole and Taiwo Fagbohungbe and Solomon Oluwole Akinola and Shamsuddeen Hassan Muhammad and others},
  eprint       ={2010.02353},
  primaryclass ={cs.CL},
  title        ={Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages},
  year         ={2020},
  pdf         ={nekoto-2020-participatory.pdf},
}

